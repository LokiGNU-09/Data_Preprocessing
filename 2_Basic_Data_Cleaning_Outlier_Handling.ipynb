{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kgfqKWByMPM"
   },
   "source": [
    "###Data cleaning is a critically important step in any machine learning project. In tabular data, there are many di\u000b",
    "erent statistical analysis and data visualization techniques you can use to explore your data in order to identify data cleaning operations you may want to perform. Before jumping to the sophisticated methods, there are some very basic data cleaning operations that you probably should perform on every single machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1nmRSZUyUY3"
   },
   "source": [
    "###After completing this section, you will know:\n",
    "\n",
    "\n",
    "*   **How to identify and remove column variables that only have a single value.**\n",
    "*   **How to identify and consider column variables with very few unique values.**\n",
    "*   **How to identify and remove rows that contain duplicate observations.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so_EoWShzOsv"
   },
   "source": [
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/oil-spill.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDYNsib9zuiS"
   },
   "source": [
    "###The dataset involves the task of predicting whether the patch contains an oil spill or not, e.g. from the illegal or accidental dumping of oil in the ocean, given a vector that describes the contents of a patch of a satellite image. There are 937 cases. Each case is comprised of 48 numerical computer vision derived features, a patch number, and a class label. The normal case is no oil spill assigned the class label of 0, whereas an oil spill is indicated by a class label of 1. There are 896 cases for no oil spill and 41 cases of an oil spill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKA4fqONx-Az",
    "outputId": "d3cfbff3-6ee7-4b84-b55a-f571327c9d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-12 11:43:22--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/oil-spill.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 230924 (226K) [text/plain]\n",
      "Saving to: ‘oil-spill.csv.2’\n",
      "\n",
      "\r",
      "oil-spill.csv.2       0%[                    ]       0  --.-KB/s               \r",
      "oil-spill.csv.2     100%[===================>] 225.51K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2021-08-12 11:43:22 (13.3 MB/s) - ‘oil-spill.csv.2’ saved [230924/230924]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/oil-spill.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZhJXadPZScKt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/oil-spill.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfHUYmoWSjM7",
    "outputId": "3b46b491-e376-4352-f09d-7bb046943902"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocjaFH1ozVuI",
    "outputId": "d34865d4-e60c-421b-9bf5-91f6d0c8ada1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/content/oil-spill.csv\",header=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "ZQ8abSgszfPH",
    "outputId": "70684695-7242-4f4f-d913-71dd7dc3e9b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>214.7</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>99.59</td>\n",
       "      <td>32.19</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.20</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>310</td>\n",
       "      <td>16110</td>\n",
       "      <td>0.00</td>\n",
       "      <td>138.68</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6058.23</td>\n",
       "      <td>4061.15</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7.09</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>704</td>\n",
       "      <td>40140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.65</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>71.20</td>\n",
       "      <td>16.73</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.29</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.79</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38.80</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>120.22</td>\n",
       "      <td>33.47</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.21</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6.78</td>\n",
       "      <td>-3.54</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>183</td>\n",
       "      <td>10080</td>\n",
       "      <td>0.00</td>\n",
       "      <td>108.27</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>289.19</td>\n",
       "      <td>48.68</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>45</td>\n",
       "      <td>2340</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.39</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1        2       3    4   ...  45        46     47    48  49\n",
       "0   1   2558  1506.09  456.63   90  ...   0  33243.19  65.74  7.95   1\n",
       "1   2  22325    79.11  841.03  180  ...   0  51572.04  65.73  6.26   0\n",
       "2   3    115  1449.85  608.43   88  ...   1  31692.84  65.81  7.84   1\n",
       "3   4   1201  1562.53  295.65   66  ...   1  37696.21  65.67  8.07   1\n",
       "4   5    312   950.27  440.86   37  ...   0  29038.17  65.66  7.35   0\n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfue6yM_efx"
   },
   "source": [
    "###This dataset contains columns with very few unique values that provides a good basis for data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6wbrZPt_QHi",
    "outputId": "08f9a7fd-e77d-44c3-995b-a37ebcc3fbe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-12 11:43:27--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4549 (4.4K) [text/plain]\n",
      "Saving to: ‘iris.csv’\n",
      "\n",
      "\r",
      "iris.csv              0%[                    ]       0  --.-KB/s               \r",
      "iris.csv            100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-08-12 11:43:27 (72.3 MB/s) - ‘iris.csv’ saved [4549/4549]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDK4bnhv_3ki"
   },
   "source": [
    "###iris flowers dataset is another standard machine learning dataset. The dataset involves predicting the flower species given measurements of iris owers in centimeters. It is a multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9U4ZXGCEUZV"
   },
   "source": [
    "###This dataset contains duplicate rows that provides a good basis for data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QKOaAt-EbFe"
   },
   "source": [
    "#**Identify Columns That Contain a Single Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqfBEowJTc_N",
    "outputId": "070079c2-03fa-4c58-fd7c-446d730ef56b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((937, 50), 937, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.shape[0], data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gd90xHJxT2j7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mA0AJ3i_T25y",
    "outputId": "182b8064-4227-42cd-e0f5-6e3eb55f91e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[22].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOUrHvY3_ltt",
    "outputId": "62f93cb5-02c5-4c74-a7c8-6b5862a81390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 238\n",
      "1 297\n",
      "2 927\n",
      "3 933\n",
      "4 179\n",
      "5 375\n",
      "6 820\n",
      "7 618\n",
      "8 561\n",
      "9 57\n",
      "10 577\n",
      "11 59\n",
      "12 73\n",
      "13 107\n",
      "14 53\n",
      "15 91\n",
      "16 893\n",
      "17 810\n",
      "18 170\n",
      "19 53\n",
      "20 68\n",
      "21 9\n",
      "22 1\n",
      "23 92\n",
      "24 9\n",
      "25 8\n",
      "26 9\n",
      "27 308\n",
      "28 447\n",
      "29 392\n",
      "30 107\n",
      "31 42\n",
      "32 4\n",
      "33 45\n",
      "34 141\n",
      "35 110\n",
      "36 3\n",
      "37 758\n",
      "38 9\n",
      "39 9\n",
      "40 388\n",
      "41 220\n",
      "42 644\n",
      "43 649\n",
      "44 499\n",
      "45 2\n",
      "46 937\n",
      "47 169\n",
      "48 286\n",
      "49 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/content/oil-spill.csv\",header=None)\n",
    "# summarize the number of unique values in each column\n",
    "for i in range(data.shape[1]):\n",
    "  print(i, len(data[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqHIO7kkEsXI",
    "outputId": "4afcbacf-f64a-4452-9d8a-febe19303774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     238\n",
      "1     297\n",
      "2     927\n",
      "3     933\n",
      "4     179\n",
      "5     375\n",
      "6     820\n",
      "7     618\n",
      "8     561\n",
      "9      57\n",
      "10    577\n",
      "11     59\n",
      "12     73\n",
      "13    107\n",
      "14     53\n",
      "15     91\n",
      "16    893\n",
      "17    810\n",
      "18    170\n",
      "19     53\n",
      "20     68\n",
      "21      9\n",
      "22      1\n",
      "23     92\n",
      "24      9\n",
      "25      8\n",
      "26      9\n",
      "27    308\n",
      "28    447\n",
      "29    392\n",
      "30    107\n",
      "31     42\n",
      "32      4\n",
      "33     45\n",
      "34    141\n",
      "35    110\n",
      "36      3\n",
      "37    758\n",
      "38      9\n",
      "39      9\n",
      "40    388\n",
      "41    220\n",
      "42    644\n",
      "43    649\n",
      "44    499\n",
      "45      2\n",
      "46    937\n",
      "47    169\n",
      "48    286\n",
      "49      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8m_rcRSJFExn"
   },
   "outputs": [],
   "source": [
    "counts = data.nunique()\n",
    "to_del = [i for i,v in enumerate(counts) if v == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "970h9F5pUp-_"
   },
   "outputs": [],
   "source": [
    "# to_del=[]\n",
    "# for i,v in enumerate(counts):\n",
    "#   if(v==1):\n",
    "#     to_del.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJwLLoFEFd8n",
    "outputId": "29a66575-0dbb-42ab-9f72-908caa06a561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\n"
     ]
    }
   ],
   "source": [
    "print(to_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdVmRBr7FhBA",
    "outputId": "cfb3a5cc-dfeb-4b2f-ea55-c70f009e16d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 49)\n"
     ]
    }
   ],
   "source": [
    "data.drop(to_del, axis=1, inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmqiYzCuGBri"
   },
   "source": [
    "#**Homework: **\n",
    "#Task: Remove all the columns with unique values are <=1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8Z-m1V7SFq6s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FOptZNHGb2s"
   },
   "source": [
    "###**Remove Columns That Have A Low Variance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xSjkrvNGKVr",
    "outputId": "ad30eed4-f8e7-421f-f48a-ae0be2af55e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 49) (937,)\n",
      "(937, 48)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# load the dataset\n",
    "data = pd.read_csv(\"/content/oil-spill.csv\",header=None)\n",
    "# split data into inputs and outputs\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "print(X.shape, y.shape)\n",
    "# define the transform\n",
    "transform = VarianceThreshold()\n",
    "# transform the input data\n",
    "X_sel = transform.fit_transform(X)\n",
    "print(X_sel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "to_pDKmPIZUv"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGKi_ZCPIrxc",
    "outputId": "344c3465-2278-4689-9652-bf1bfd1c1e00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "thresholds = np.arange(0.0, 0.55, 0.05)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qwFB_0DIu9I",
    "outputId": "985d25a2-f7cc-4a1d-a934-4ebae0da4d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 49) (937,)\n",
      "Threshold=0.0, Features=48\n",
      "Threshold=0.05, Features=37\n",
      "Threshold=0.1, Features=36\n",
      "Threshold=0.15000000000000002, Features=35\n",
      "Threshold=0.2, Features=35\n",
      "Threshold=0.25, Features=35\n",
      "Threshold=0.30000000000000004, Features=35\n",
      "Threshold=0.35000000000000003, Features=35\n",
      "Threshold=0.4, Features=35\n",
      "Threshold=0.45, Features=33\n",
      "Threshold=0.5, Features=31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# load the dataset\n",
    "data = pd.read_csv(\"/content/oil-spill.csv\",header=None)\n",
    "# split data into inputs and outputs\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "print(X.shape, y.shape)\n",
    "results = []\n",
    "for t in thresholds:\n",
    "  # define the transform\n",
    "  transform = VarianceThreshold(threshold=t)\n",
    "  # transform the input data\n",
    "  X_sel = transform.fit_transform(X)\n",
    "  # determine the number of input features\n",
    "  n_features = X_sel.shape[1]\n",
    "  print('Threshold={}, Features={}'.format(t, n_features))\n",
    "  # store the result\n",
    "  results.append(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgFP90hjHyrX"
   },
   "source": [
    "##**Delete Rows That Contain Duplicate Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCTnZrxgIA50"
   },
   "source": [
    "###If your dataset simply has duplicate rows, there is no need to worry about preserving the data; it is already a part of the finished dataset and you can merely remove or drop these rows from your cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpcilms_G8p7",
    "outputId": "c258f879-1ab7-48a2-e070-bdd78c41c703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n",
      "(147, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/iris.csv', header=None)\n",
    "print(df.shape)\n",
    "# delete duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WJ0qnCC-IOXR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUT-MofaJnA1"
   },
   "source": [
    "#**Outlier Identification and Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZK_i7ASWJ2tU"
   },
   "source": [
    "###When modeling, it is important to clean the data sample to ensure that the observations best represent the problem. Sometimes a dataset can contain extreme values that are outside the range of what is expected and unlike the other data. These are called outliers and often machine learning modeling and model skill in general can be improved by understanding and even removing these outlier values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Od2zIooLLM_Y"
   },
   "outputs": [],
   "source": [
    "columns = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qF5HF4QLbA3",
    "outputId": "e0e7d28b-8b8d-430f-9229-414100f6c2d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns.pop()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Gi2IpJWMJq5l",
    "outputId": "4a3309d2-ef7d-424f-8b77-83d842a9bd68"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 5))\n",
    "fig.suptitle(\"All Features vs Class\")\n",
    "\n",
    "for index, column in enumerate(columns):\n",
    "    sns.boxplot(x=df[column], ax=ax[index])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTg9lXotMJcF",
    "outputId": "183a2b54-d318-4a94-bd63-95cb2ee183fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower = 1.7447561925148656 and upper = 4.366808433335477\n"
     ]
    }
   ],
   "source": [
    "data_mean, data_std = df[1].mean(), df[1].std()\n",
    "# define outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "print(\"lower = {} and upper = {}\".format(lower,upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sQwdAx5hUxq",
    "outputId": "8536a24d-4980-43b6-a8d0-687030b81b42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGQplktgPisx",
    "outputId": "9a6dda0f-4e19-4637-deb6-41b9f760e33d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[df[1] < upper]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SicEAerPKGf",
    "outputId": "0da2f38f-96f4-4b4a-ea28-e29b92ad8c04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df[new_df[1] > lower]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "v9v9CPEkjpD6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jO4oSLtBEIth"
   },
   "source": [
    "#**Handling Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHL9Bu9-EMyz"
   },
   "source": [
    "###Real-world data often has missing values. Data can have missing values for a number of reasons such as observations that were not recorded and data corruption. Handling missing data is important as many machine learning algorithms do not support data with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIclEQ-oEcnQ"
   },
   "source": [
    "###**Dataset Used :** Most popular one - Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpsFNjTiEMAh",
    "outputId": "e33ae99c-17be-4921-c0de-864835206333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-12 11:43:50--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23278 (23K) [text/plain]\n",
      "Saving to: ‘pima-indians-diabetes.csv’\n",
      "\n",
      "\r",
      "          pima-indi   0%[                    ]       0  --.-KB/s               \r",
      "pima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2021-08-12 11:43:50 (18.7 MB/s) - ‘pima-indians-diabetes.csv’ saved [23278/23278]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sksoqsrcE8RT",
    "outputId": "b6ae21a1-3f7b-4298-fcf2-27611061cb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2  ...           6           7           8\n",
      "count  768.000000  768.000000  768.000000  ...  768.000000  768.000000  768.000000\n",
      "mean     3.845052  120.894531   69.105469  ...    0.471876   33.240885    0.348958\n",
      "std      3.369578   31.972618   19.355807  ...    0.331329   11.760232    0.476951\n",
      "min      0.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n",
      "25%      1.000000   99.000000   62.000000  ...    0.243750   24.000000    0.000000\n",
      "50%      3.000000  117.000000   72.000000  ...    0.372500   29.000000    0.000000\n",
      "75%      6.000000  140.250000   80.000000  ...    0.626250   41.000000    1.000000\n",
      "max     17.000000  199.000000  122.000000  ...    2.420000   81.000000    1.000000\n",
      "\n",
      "[8 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "import pandas as pd\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('/content/pima-indians-diabetes.csv', header=None)\n",
    "# summarize the dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UFoTPw_FJWF",
    "outputId": "92e24712-e072-4928-edf9-1a61d7ae67a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "Xl_XiOQ1FMAJ",
    "outputId": "85f07b07-69a4-4377-cc51-1d2b250a19ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2   3    4     5      6   7  8\n",
       "0    6  148  72  35    0  33.6  0.627  50  1\n",
       "1    1   85  66  29    0  26.6  0.351  31  0\n",
       "2    8  183  64   0    0  23.3  0.672  32  1\n",
       "3    1   89  66  23   94  28.1  0.167  21  0\n",
       "4    0  137  40  35  168  43.1  2.288  33  1\n",
       "5    5  116  74   0    0  25.6  0.201  30  0\n",
       "6    3   78  50  32   88  31.0  0.248  26  1\n",
       "7   10  115   0   0    0  35.3  0.134  29  0\n",
       "8    2  197  70  45  543  30.5  0.158  53  1\n",
       "9    8  125  96   0    0   0.0  0.232  54  1\n",
       "10   4  110  92   0    0  37.6  0.191  30  0\n",
       "11  10  168  74   0    0  38.0  0.537  34  1\n",
       "12  10  139  80   0    0  27.1  1.441  57  0\n",
       "13   1  189  60  23  846  30.1  0.398  59  1\n",
       "14   5  166  72  19  175  25.8  0.587  51  1\n",
       "15   7  100   0   0    0  30.0  0.484  32  1\n",
       "16   0  118  84  47  230  45.8  0.551  31  1\n",
       "17   7  107  74   0    0  29.6  0.254  31  1\n",
       "18   1  103  30  38   83  43.3  0.183  33  0\n",
       "19   1  115  70  30   96  34.6  0.529  32  1"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOq0USQBFVch",
    "outputId": "b2830d75-6aa4-437e-fba9-7453692ea4c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the number of missing values for each column\n",
    "num_missing = (dataset[[1,2,3,4,5]] == 0).sum()\n",
    "# report the results\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uo06hsQOFh5v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "1sIFuQD5Fpf9",
    "outputId": "89a02ff8-a837-4397-d3d4-e5c8369fa615"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6   7  8\n",
       "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
       "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
       "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
       "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
       "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
       "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
       "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
       "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
       "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
       "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
       "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
       "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
       "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
       "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
       "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
       "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
       "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
       "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
       "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
       "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPE-AYhOFxQG",
    "outputId": "d6ea54b6-ff4c-4027-db4c-98adf60fa57d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nonFNW7fF2Bq"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:8].values\n",
    "y = dataset.iloc[:,8].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-cR7YzgGc5m",
    "outputId": "c57ddae4-1304-44f7-cbd9-90fe0b8544e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keCvVhaEGy9r"
   },
   "source": [
    "#**Missing Values Cause Problems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "iyj4QJkrGfNz",
    "outputId": "2032328e-f7e4-4ded-e44b-a3a597945c0b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4076c5527b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msl02G2gG8cu"
   },
   "source": [
    "###Many popular predictive models such as support vector machines, the glmnet, and neural networks, cannot tolerate any amount of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwQHfmugHBHK"
   },
   "source": [
    "##**Remove Rows With Missing Values**\n",
    "###The simplest strategy for handling missing data is to remove records that contain a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDZp6IgaHUNT",
    "outputId": "464b734b-26df-4a7e-f5eb-df37d7564b54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oby-kz5eGuEV",
    "outputId": "fa68602e-b880-446e-e72a-83c6afb1cf6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "sZwNbkNEHlqY"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:8].values\n",
    "y = dataset.iloc[:,8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWaeYwhrHXbM",
    "outputId": "e8022309-bf1e-4839-a51c-17f06f852e12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "fgTyvOAGICSA"
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "y9Xxu1seHgCJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,  cohen_kappa_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlfYBs2pIBW7",
    "outputId": "41827f54-a853-4f72-b07c-0fd718fa71b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       262\n",
      "           1       0.75      0.55      0.63       130\n",
      "\n",
      "    accuracy                           0.79       392\n",
      "   macro avg       0.77      0.73      0.74       392\n",
      "weighted avg       0.78      0.79      0.78       392\n",
      "\n",
      "Accuracy : 78.8265306122449\n",
      "Cohen Kappa : 0.4876220472440945\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report : \\n\",classification_report(y, y_preds))\n",
    "print(\"Accuracy :\", accuracy_score(y, y_preds) * 100)\n",
    "print(\"Cohen Kappa :\", cohen_kappa_score(y, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDG_DgqlIeOx"
   },
   "source": [
    "###Removing rows with missing values can be too limiting on some predictive modeling problems, an alternative is to impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ooK8rRi-IVvi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51Mol-o5IsU2"
   },
   "source": [
    "#**Statistical Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o-z29s-JBxK"
   },
   "source": [
    "###A dataset may have missing values. These are rows of data where one or more values or columns in that row are not present. The values may be missing completely or they may be marked with a special character or value, such as a question mark (\\?\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkNoMc7IJgM8"
   },
   "source": [
    "###Values could be missing for many reasons, often specific to the problem domain, and might include reasons such as corrupt measurements or data unavailability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSjLx4JAKJik"
   },
   "source": [
    "###Most machine learning algorithms require numeric input values, and a value to be present for each row and column in a dataset. As such, missing values can cause problems for machine learning algorithms. Because of this, it is common to identify missing values in a dataset and replace them with a numeric value. This is called data imputing, or missing data imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0dibK1HKhq7"
   },
   "source": [
    "###A simple and popular approach to data imputation involves using statistical methods to estimate a value for a column from those values that are present, then replace all missing values in the column with the calculated statistic.\n",
    "\n",
    "\n",
    "\n",
    "*   The column mean value.\n",
    "*   The column median value.\n",
    "*   The column mode value.\n",
    "*   A constant value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Z3M1oVcyIuUt"
   },
   "outputs": [],
   "source": [
    "# load and summarize the dataset\n",
    "import pandas as pd\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('/content/pima-indians-diabetes.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "OeixjXGqL4vX"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "PV3Pifu7MDul"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sll7w1gMRYo",
    "outputId": "7fea0e77-dbfd-4fd7-9d25-f59379da2928"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EISK1XhWNxP7",
    "outputId": "9d1cb85f-3fc9-410a-b63d-663fad86b951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "05aabFRgMb8L"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "lu6YzVPRM1S2"
   },
   "outputs": [],
   "source": [
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "# summarize total missing\n",
    "#print('Missing: %d' % sum(np.isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VkEMJ56Ox7o",
    "outputId": "3e83faa9-6c19-4415-b6f2-5f4456ab2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(Xtrans).isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76vnGNiePAKs",
    "outputId": "b30078a6-27f5-41bd-fa3f-48bc8eebaf46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrans).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxkwm_4wNFM8",
    "outputId": "022c97f4-c3b0-4f46-85a4-2d9c1fe5591b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "zdiDEzB7NKXl"
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(Xtrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LbY0jCUDNJfa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,  cohen_kappa_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGL0gdsROQxC",
    "outputId": "610277e9-d629-433e-cc1f-befc44b91435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       500\n",
      "           1       0.74      0.57      0.65       268\n",
      "\n",
      "    accuracy                           0.78       768\n",
      "   macro avg       0.77      0.73      0.75       768\n",
      "weighted avg       0.78      0.78      0.77       768\n",
      "\n",
      "Accuracy : 78.25520833333334\n",
      "Cohen Kappa : 0.49475276543443325\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report : \\n\",classification_report(y, y_preds))\n",
    "print(\"Accuracy :\", accuracy_score(y, y_preds) * 100)\n",
    "print(\"Cohen Kappa :\", cohen_kappa_score(y, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUK99HUHPzmh"
   },
   "source": [
    "#**Homework**:\n",
    "###strategies = ['mean', 'median', 'most_frequent', 'constant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "E3XSodaUM5BU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPYhpN20QLR-"
   },
   "source": [
    "#**Use KNN Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7lAPg_SQgcw"
   },
   "source": [
    "###Datasets may have missing values, and this can cause problems for many machine learning algorithms. As such, it is good practice to identify and replace missing values for each column in your input data prior to modeling your prediction task. This is called missing data imputation, or imputing for short. A popular approach to missing data imputation is to use a model to predict the missing values. This requires a model to be created for each input variable that has missing values. Although any one among a range of di\u000b",
    "erent models can be used to predict the missing values, the k-nearest neighbor (KNN) algorithm has proven to be generally e\u000b",
    "ective, often referred to as nearest neighbor imputation. In this tutorial, you will discover how to use nearest neighbor imputation strategies for missing data in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoCw8LdoQuEw"
   },
   "source": [
    "###Missing values must be marked with NaN values and can be replaced with nearest neighbor estimated values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HElNS34gRJ6y"
   },
   "source": [
    "###If input variables are numeric, then regression models can be used for prediction, and this case is quite common. A range of di\u000b",
    "erent models can be used, although a simple k-nearest neighbor (KNN) model has proven to be effective in experiments. The use of a KNN model to predict or fill missing values is referred to as Nearest Neighbor Imputation or KNN imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "3aLYKPucQNGN"
   },
   "outputs": [],
   "source": [
    "# load and summarize the dataset\n",
    "import pandas as pd\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('/content/pima-indians-diabetes.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ejERUdUlTFt9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "4g_bqzzAS96O"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC6o-7F_TUhL"
   },
   "source": [
    "###The KNNImputer is a data transform that is first configured based on the method used to estimate the missing values. The default distance measure is a Euclidean distance measure that is NaN aware, e.g. will not include NaN values when calculating the distance between members of the training dataset. This is set via the metric argument. The number of neighbors is set to five by default and can be configured by the n neighbors argument.<br/><br/>\n",
    "###Finally, the distance measure can be weighed proportional to the distance between instances (rows), although this is set to a uniform weighting by default, controlled via the weights argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Evctrmm4TJmR"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "YBnlxc-gTlfu"
   },
   "outputs": [],
   "source": [
    "imputer = KNNImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "8HenlUJeTr6I"
   },
   "outputs": [],
   "source": [
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhpgLUqkT3bl",
    "outputId": "556fbc01-cbf5-4389-ee56-632f5f5772b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(Xtrans).isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKiv078OT7iB",
    "outputId": "7265c80a-fb06-4f2d-9667-8b0fb378df57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "HLjvrdcdUKCV"
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(Xtrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dc5F5CSqUAE3",
    "outputId": "8a4f19b4-f7a6-4c47-cb06-6582a6b774e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       500\n",
      "           1       0.71      0.58      0.64       268\n",
      "\n",
      "    accuracy                           0.77       768\n",
      "   macro avg       0.75      0.73      0.73       768\n",
      "weighted avg       0.76      0.77      0.76       768\n",
      "\n",
      "Accuracy : 76.953125\n",
      "Cohen Kappa : 0.4712636524877867\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report : \\n\",classification_report(y, y_preds))\n",
    "print(\"Accuracy :\", accuracy_score(y, y_preds) * 100)\n",
    "print(\"Cohen Kappa :\", cohen_kappa_score(y, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7FoKNyoUjKh"
   },
   "source": [
    "#**Homework :** Repeat above things on below given dataset\n",
    "\n",
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "9Lw98PRCUPZe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBVvTUdzIi6u"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "kiU8_Iw_409K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4_cSzQb8IN8"
   },
   "source": [
    "#**HOT-DECK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtWizax673FW"
   },
   "source": [
    "###This is where a missing value is imputed from a randomly selected similar record. A form of hot-deck imputation is Last Observation Carried Forward (LOCF imputation). What LOCF does is it finds the first missing value then imputes the missing value using the cell value that is immediately prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "wnN1ZRgt8LBR"
   },
   "outputs": [],
   "source": [
    "# load and summarize the dataset\n",
    "import pandas as pd\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('/content/pima-indians-diabetes.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "H0wo2IS78pXO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDfYW7IS8-Vu"
   },
   "source": [
    "###Now we will perform LOCF on this dataframe and this should impute all the missing values using the cell above the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "CrdSeVVA8zaN"
   },
   "outputs": [],
   "source": [
    "# looking at the data after imputation\n",
    "dataset.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Mo4otWmt9NJs"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FUnKhjT9BsS",
    "outputId": "c704d60b-9d22-4d4b-9edc-6fe2c31df674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    3\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(X).isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "DBKCqhd29PtQ"
   },
   "outputs": [],
   "source": [
    "dataset.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "XN7MuJ75_OKJ"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvCj_nu2_RY3",
    "outputId": "23e8bba6-d46d-4db9-a427-dd5567a79860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(X).isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPcx_ow__ua7"
   },
   "source": [
    "#**Cold Deck Imputation:**\n",
    "###This technique consists in replace the missing value for one constant from an external source, such as a value from a previous realization of the same survey. This technique is similar to substitution, but in this case, a constant value is used and in the substitution technique different values can be used to substitute the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAnlPr6LARvA"
   },
   "source": [
    "#**Homework:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "3iWmaf-W_T96"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_Basic_Data_Cleaning_Outlier_Handling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
